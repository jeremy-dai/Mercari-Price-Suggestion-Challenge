{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mercari Price Suggestion Challenge\n",
    "- Task: Build an algorithm that automatically suggests the right product prices. \n",
    "- Data: User-inputted text descriptions of their products, including details like product category name, brand name, and item condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import xgboost\n",
    "from scipy import sparse\n",
    "import xgboost\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Data\n"
     ]
    }
   ],
   "source": [
    "print ('Importing Data')\n",
    "current_t = time.time()\n",
    "train_data = pd.read_table('data/train.tsv')\n",
    "test_data = pd.read_table('data/test.tsv')\n",
    "print(\"Data Imported. Time elapsed: \" + str(int(time.time()-current_t )) + \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def category(data):\n",
    "    cat = data.category_name.str.split('/', expand = True)\n",
    "    data[\"main_cat\"] = cat[0]\n",
    "    data[\"subcat1\"] = cat[1]\n",
    "    data[\"subcat2\"] = cat[2]\n",
    "    try:\n",
    "        data[\"subcat3\"] = cat[3]\n",
    "    except:\n",
    "        data[\"subcat3\"] = np.nan  \n",
    "    try:\n",
    "        data[\"subcat4\"] = cat[4]\n",
    "    except:\n",
    "        data[\"subcat4\"] = np.nan  \n",
    "        \n",
    "def missing_data(data, _value = 'None'):\n",
    "    # Handle missing data\n",
    "    for col in data.columns:\n",
    "        data[col].fillna(_value,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category(train_features)\n",
    "category(test_features)\n",
    "\n",
    "missing_data(train_features)\n",
    "missing_data(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## convert categorical var to numeric \n",
    "le = preprocessing.LabelEncoder()\n",
    "def cat_to_num(train,test):\n",
    "    suf=\"_le\"\n",
    "    for col in ['brand_name','main_cat','subcat1','subcat2','subcat3','subcat4']:\n",
    "        train[col+suf] = le.fit_transform(train[col])\n",
    "        dic = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "        test[col+suf] = test[col].map(dic).fillna(0).astype(int) \n",
    "        \n",
    "        print(\"{} is transformed to {}\".format(col,col+suf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_to_num(train_features,test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Length of item discription\n",
    "train_features['Length_of_item_description']=train_features['item_description'].apply(len)\n",
    "test_features['Length_of_item_description']=test_features['item_description'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Combine numeric features\n",
    "def numeric_to_features(data):\n",
    "    numeric_features = list(data.apply(lambda x:(x['shipping'],x['item_condition_id'],x['main_cat_le'],\\\n",
    "                                                 x['subcat1_le'],x['subcat2_le'],x['subcat3_le'],\\\n",
    "                                                 x['subcat4_le'],x['Length_of_item_description'],\\\n",
    "                                                 x['brand_name_le']), axis=1))\n",
    "    return numeric_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_numeric_features = numeric_to_features(train_features)\n",
    "test_numeric_features = numeric_to_features(test_features)\n",
    "print (\"Numeric Features created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_process(data):\n",
    "    # Process text    \n",
    "    # make item_description and name lower case    \n",
    "    text = list(data.apply(lambda x:'%s %s' %(x['item_description'],x['name']), axis=1))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text =text_process(train_features)\n",
    "test_text =text_process(test_features)\n",
    "print (\"Text Features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tfidf\n",
    "    # save the vectorize\n",
    "    # pickle.dump(tfidf,open('vectorizer.pkl', \"bw\",-1))\n",
    "    # tfidf=pickle.load(open('vectorizer.pkl','br'))\n",
    "    \n",
    "# check if we should use max_features parameter\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True,ngram_range=(1,3), stop_words = 'english',max_features = 5000)\n",
    "train_text_features = tfidf.fit_transform(train_text)\n",
    "test_text_features = tfidf.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Stacker for sparse data\n",
    "print (\"Stacking features\")\n",
    "train_final_features = sparse.hstack((train_numeric_features,train_text_features))\n",
    "test_final_features = sparse.hstack((test_numeric_features,test_text_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# save the features\n",
    "pickle.dump(train_final_features,open('train_features.pkl', \"bw\"))\n",
    "pickle.dump(test_final_features,open('test_features.pkl', \"bw\"))\n",
    "pickle.dump(train_labels,open('train_labels.pkl', \"bw\"))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick and Tune the Algorithms\n",
    "\n",
    "An algorithm may be highly sensitive to some of its features. The choose of good parameters may have a dominant effect on the algorithm performance. \n",
    "\n",
    "In this study, we use GridSearchCV to fine tune the algorithm. I start with default parameters and level it up and down. Based on the GridSearchCV function I will adjust the parameters again. For example, if the GridSearchCV chooses the smallest value for the parameter, I will add a smaller number in the search list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "train_final_features = pickle.load(open('train_features.pkl','br'))\n",
    "test_final_features = pickle.load(open('test_features.pkl','br'))\n",
    "train_labels = pickle.load(open('train_labels.pkl','br'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBRegressor(n_estimators=500, \n",
    "                           learning_rate=0.1, \n",
    "                           gamma=0,subsample=0.8,\n",
    "                           colsample_bytree=1,\n",
    "                           min_child_weight=1, \n",
    "                           max_depth=20,\n",
    "                           nthread=4,\n",
    "                           seed=1505)\n",
    "\n",
    "X = (train_final_features)\n",
    "Y = (train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_t = time.time()\n",
    "xgb.fit(X,Y)\n",
    "print(\"Modeling complete. Time elapsed: \" + str(int(time.time()-current_t)) + \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gridsearchcv\n",
    "'''\n",
    "print(\"Initiating grid search\")\n",
    "xgb = XGBRegressor(n_jobs=4)\n",
    "param_grid = { \"n_estimators\" : [1000],\n",
    "                \"max_depth\" : [38], #17-11\n",
    "                \"min_child_weight\" : [11],\n",
    "                \"subsample\":[ .8] #subsample ＝ 30%～80% of training set；\n",
    "                \"gamma\":[0,0.1,0.2,0.5]\n",
    "                 \"learning_rate\":[.055,.060,.065] #learning_rate ＝ 0.1 or smaller\n",
    "                 \"subsample\" :[i/10.0 for i in [2,4,8]] \n",
    "                 \"tree_depth\" : [2,8]\n",
    "                   }\n",
    "CV_xgb = GridSearchCV(estimator=xgb, param_grid=param_grid,verbose=1)\n",
    "\n",
    "CV_xgb.fit(X_train, y_train)\n",
    "\n",
    "print(CV_xgb.best_params_,CV_xgb.best_score_) \n",
    "print(\"All tasks complete.\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# vectorized error calc\n",
    "def rmsle(y, y0):\n",
    "    assert len(y) == len(y0)\n",
    "    return np.sqrt(np.mean(np.power(np.log1p(y)-np.log1p(y0), 2)))\n",
    "    \n",
    "# test\n",
    "def test_reg(reg, features, labels):\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(\\\n",
    "                features, labels, test_size=0.8, random_state=0)\n",
    "    ### fit the classifier using training set, and test on test set\n",
    "    reg.fit(features_train, (labels_train))\n",
    "    y_true = labels_test\n",
    "    y_pred = (reg.predict(features_test))\n",
    "    y_pred[y_pred<0]=0\n",
    "    jag=rmsle(y_true,y_pred)\n",
    "    print(jag)\n",
    "\n",
    "\n",
    "test_reg(xgb, train_final_features, train_labels)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outfile_name = 'submit.csv'\n",
    "\n",
    "pred_label = xgb.predict(test_final_features)\n",
    "pred_label = np.exp(pred_label)\n",
    "pred_label = pd.DataFrame(np.array(pred_label), columns = ['price'])\n",
    "pred_label.index.name = 'test_id'\n",
    "pred_label.to_csv(outfile_name, encoding='utf-8')\n",
    "print ('Modeling done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
